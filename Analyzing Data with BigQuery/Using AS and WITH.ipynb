{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/as-with).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nYou are getting to the point where you can own an analysis from beginning to end. So you'll do more data exploration in this exercise than you've done before.  Before you get started, run the following set-up code as usual. ","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex5 import *\nprint(\"Setup Complete\")","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You'll work with a dataset about taxi trips in the city of Chicago. Run the cell below to fetch the `chicago_taxi_trips` dataset.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"chicago_taxi_trips\" dataset\ndataset_ref = client.dataset(\"chicago_taxi_trips\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Using Kaggle's public dataset BigQuery integration.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exercises\n\nYou are curious how much slower traffic moves when traffic volume is high. This involves a few steps.\n\n### 1) Find the data\nBefore you can access the data, you need to find the table name with the data.\n\n*Hint*: Tab completion is helpful whenever you can't remember a command. Type `client.` and then hit the tab key. Don't forget the period before hitting tab.","metadata":{}},{"cell_type":"code","source":"# Your code here to find the table name","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List all the tables in the dataset\ntables = list(client.list_tables(dataset))\n\n# Print names of all tables in the dataset (there is only one!)\nfor table in tables:  \n    print(table.table_id)\n\ntable_name = 'taxi_trips'# Write the table name as a string below\n\n# Check your answer\nq_1.check()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"taxi_trips\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"1_GetTableName\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2) Peek at the data\n\nUse the next code cell to peek at the top few rows of the data. Inspect the data and see if any issues with data quality are immediately obvious. ","metadata":{}},{"cell_type":"code","source":"# Your code here\n# Construct a reference to the \"taxi_trips\" table\ntable_ref = dataset_ref.table(\"taxi_trips\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"taxi_trips\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) Determine when this data is from\n\nIf the data is sufficiently old, we might be careful before assuming the data is still relevant to traffic patterns today. Write a query that counts the number of trips in each year.  \n\nYour results should have two columns:\n- `year` - the year of the trips\n- `num_trips` - the number of trips in that year\n\nHints:\n- When using **GROUP BY** and **ORDER BY**, you should refer to the columns by the alias `year` that you set at the top of the **SELECT** query.\n- The SQL code to **SELECT** the year from `trip_start_timestamp` is <code>SELECT EXTRACT(YEAR FROM trip_start_timestamp)</code>\n- The **FROM** field can be a little tricky until you are used to it.  The format is:\n    1. A backick (the symbol \\`).\n    2. The project name. In this case it is `bigquery-public-data`.\n    3. A period.\n    4. The dataset name. In this case, it is `chicago_taxi_trips`.\n    5. A period.\n    6. The table name. You used this as your answer in **1) Find the data**.\n    7. A backtick (the symbol \\`).","metadata":{}},{"cell_type":"code","source":"rides_per_year_query = \"\"\"\n                       SELECT EXTRACT(YEAR FROM trip_start_timestamp) AS year, \n                              COUNT(1) AS num_trips\n                       FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                       GROUP BY year\n                       ORDER BY year\n                       \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nrides_per_year_query_job = client.query(rides_per_year_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nrides_per_year_result = rides_per_year_query_job.to_dataframe()\n\n# Check your answer\nq_3.check()","metadata":{"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"3_YearDistrib\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 4) Dive slightly deeper\n\nYou'd like to take a closer look at rides from 2017.  Copy the query you used above in `rides_per_year_query` into the cell below for `rides_per_month_query`.  Then modify it in two ways:\n1. Use a **WHERE** clause to limit the query to data from 2017.\n2. Modify the query to extract the month rather than the year.","metadata":{}},{"cell_type":"code","source":"rides_per_month_query = \"\"\"\n                        SELECT EXTRACT(MONTH FROM trip_start_timestamp) AS month, \n                               COUNT(1) AS num_trips\n                        FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                        WHERE EXTRACT(YEAR FROM trip_start_timestamp) = 2017\n                        GROUP BY month\n                        ORDER BY month\n                        \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nrides_per_month_query_job = client.query(rides_per_month_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nrides_per_month_result = rides_per_month_query_job.to_dataframe()\n\nq_4.check()","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"4_MonthDistrib\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 5) Write the query\n\nIt's time to step up the sophistication of your queries.  Write a query that shows, for each hour of the day in the dataset, the corresponding number of trips and average speed.\n\nYour results should have three columns:\n- `hour_of_day` - sort by this column, which holds the result of extracting the hour from `trip_start_timestamp`.\n- `num_trips` - the count of the total number of trips in each hour of the day (e.g. how many trips were started between 6AM and 7AM, independent of which day it occurred on).\n- `avg_mph` - the average speed, measured in miles per hour, for trips that started in that hour of the day.  Average speed in miles per hour is calculated as `3600 * SUM(trip_miles) / SUM(trip_seconds)`. (The value 3600 is used to convert from seconds to hours.)\n\nRestrict your query to data meeting the following criteria:\n- a `trip_start_timestamp` between **2017-01-01** and **2017-07-01**\n- `trip_seconds` > 0 and `trip_miles` > 0\n\nYou will use a common table expression (CTE) to select just the relevant rides.  Because this dataset is very big, this CTE should select only the columns you'll need to create the final output (though you won't actually create those in the CTE -- instead you'll create those in the later **SELECT** statement below the CTE).\n\nThis is a much harder query than anything you've written so far.  Good luck!","metadata":{}},{"cell_type":"code","source":"speeds_query = \"\"\"\n               WITH RelevantRides AS\n               (\n                   SELECT EXTRACT(HOUR FROM trip_start_timestamp) AS hour_of_day, \n                          trip_miles, \n                          trip_seconds\n                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                   WHERE trip_start_timestamp > '2017-01-01' AND \n                         trip_start_timestamp < '2017-07-01' AND \n                         trip_seconds > 0 AND \n                         trip_miles > 0\n               )\n               SELECT hour_of_day, \n                      COUNT(1) AS num_trips, \n                      3600 * SUM(trip_miles) / SUM(trip_seconds) AS avg_mph\n               FROM RelevantRides\n               GROUP BY hour_of_day\n               ORDER BY hour_of_day\n               \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nspeeds_query_job = client.query(speeds_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nspeeds_result = speeds_query_job.to_dataframe()\n\n# View results\nprint(speeds_result)\n\n# Check your answer\nq_5.check()","metadata":{"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:440: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n  \"Cannot create BigQuery Storage client, the dependency \"\n","output_type":"stream"},{"name":"stdout","text":"    hour_of_day  num_trips    avg_mph\n0             0     319339  20.230524\n1             1     266529  18.937621\n2             2     210147  18.777070\n3             3     159668  20.158048\n4             4     122183  26.736014\n5             5     119312  30.769172\n6             6     182738  24.588313\n7             7     358406  17.735967\n8             8     541775  15.079892\n9             9     565548  16.543882\n10           10     525120  18.539614\n11           11     594603  18.928379\n12           12     622324  17.838745\n13           13     630181  17.671089\n14           14     622465  16.974239\n15           15     640430  15.688418\n16           16     701435  14.283888\n17           17     756627  12.462955\n18           18     768251  13.646810\n19           19     701064  16.642882\n20           20     598614  19.536777\n21           21     552726  20.433874\n22           22     501095  19.531374\n23           23     399587  19.877046\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.16666666666666666, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"5_TheLongQuery\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"cell_type":"markdown","source":"For the solution, uncomment the appropriate line below.","metadata":{}},{"cell_type":"markdown","source":"# Keep going\n\nYou can write very complex queries now with a single data source. But nothing expands the horizons of SQL as much as the ability to combine or **JOIN** tables.\n\n**[Click here](https://www.kaggle.com/dansbecker/joining-data)** to start the last lesson in the Intro to SQL micro-course.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161314) to chat with other Learners.*","metadata":{}}]}